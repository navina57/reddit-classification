{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1464a1-dee4-423a-ab7b-224ddf512af5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd47821-32dc-4993-8192-5b7c8073aac1",
   "metadata": {},
   "source": [
    "**THIS NOTEBOOK USES REQUESTS TO GET DATA FROM REDDITS API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bebef4b-28a3-4c25-971f-f8a0c61de3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "import getpass \n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6daff-8e9c-40f1-8169-75611f9200dd",
   "metadata": {},
   "source": [
    "### API credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c674f24-59d0-42ad-b787-066d274637c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "client_id = 'NSeSVr03ZJ8ov2YBVvK6vw'\n",
    "client_secret =  'VJbMqoBH0yMzhUXtvrtBUY6IgwLcXQ'\n",
    "user_agent = 'navi dsb-826'\n",
    "username = 'OkCommunity6752'\n",
    "password =  getpass.getpass() # reddit password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbd88f6-2110-4a50-abda-e1ddb9c304ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get access token \n",
    "def get_token():\n",
    "    auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "    data = {\n",
    "        'grant_type': 'password',\n",
    "        'username': username,\n",
    "        'password': password\n",
    "    }\n",
    "    # Create an informative header for your application\n",
    "    headers = {'User-Agent': 'navina/0.0.1'}\n",
    "\n",
    "    res = requests.post(\n",
    "        'https://www.reddit.com/api/v1/access_token',\n",
    "        auth=auth,\n",
    "        data=data,\n",
    "        headers=headers)\n",
    "    \n",
    "    # Retrieve access token\n",
    "    token = res.json()['access_token']\n",
    "    return token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfcc2f08-cf85-4267-98b9-b57e174e6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get posts from subreddit\n",
    "def get_posts(subreddit, token, limit=100, before = None):\n",
    "    headers = {'Authorization': f'bearer {token}', 'User-Agent': user_agent}\n",
    "    url = f'https://oauth.reddit.com/r/{subreddit}/new'\n",
    "    params = {'limit': limit, 'before': before, 'sort': 'created', 'sort_order': 'asc'}\n",
    "\n",
    "    print(f\"Requesting posts from r/{subreddit}\")\n",
    "    res = requests.get(url, headers=headers, params=params)\n",
    "    # Check if the request was successful\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code}: {res.text}\")\n",
    "        return pd.DataFrame(), None  # Return an empty DataFrame on error\n",
    "\n",
    "    print(f\"Received response from r/{subreddit}\")\n",
    "    posts = res.json()['data']['children']\n",
    "    after = res.json()['data']['before'] \n",
    "\n",
    "    posts_list = []\n",
    "    for post in posts: \n",
    "        post_list = post['data']\n",
    "        if post_list['title'] and post_list['selftext']:\n",
    "            posts_list.append({\n",
    "                'subreddit': subreddit, \n",
    "                'title': post_list['title'],\n",
    "                'body': post_list['selftext'],\n",
    "                'created': post_list['created_utc'],\n",
    "                'score': post_list['score'],\n",
    "                'num_comments': post_list['num_comments'],\n",
    "                'id': post_list['id']\n",
    "            })\n",
    "    print(f\"Parsed {len(posts_list)} posts from r/{subreddit}\")\n",
    "    return pd.DataFrame(posts_list), before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a54f48-c0d4-43e2-b098-5bd627887984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter unique posts\n",
    "def unique_filter(df, new_posts):\n",
    "    # filtering based on ID rather than all columns, two posts can be created at the same time but ID is unique for every post \n",
    "    return new_posts[~new_posts['id'].isin(df['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f702822-c4f9-40bf-9fe0-505b98a39b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2099 posts loaded from subreddit_posts.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the existing csv\n",
    "try:\n",
    "    all_posts = pd.read_csv('subreddit_posts.csv')\n",
    "    print(f'{len(all_posts)} posts loaded from subreddit_posts.csv')\n",
    "# Create new dataframe if file is not found\n",
    "except FileNotFoundError:\n",
    "    all_posts = pd.DataFrame(columns=['subreddit', 'title', 'body', 'created', 'score', 'num_comments', 'id'])\n",
    "    print('File not found. Creating a new file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35f6df0-c932-4f05-be23-1e479e1adea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify what the last post IDs for each subreddit were\n",
    "last_personalfinance_id = all_posts[all_posts['subreddit'] == 'personalfinance']['id'].min() if 'id' in all_posts.columns else None\n",
    "last_investing_id = all_posts[all_posts['subreddit'] == 'investing']['id'].min() if 'id' in all_posts.columns else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3672d-e6e4-4aae-98d4-c95c8965fe86",
   "metadata": {},
   "source": [
    "### Pull data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02057d79-ff32-4f2b-bc77-59452fa67e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Loop...\n",
      "Requesting posts from r/personalfinance\n",
      "Received response from r/personalfinance\n",
      "Parsed 100 posts from r/personalfinance\n",
      "Requesting posts from r/investing\n",
      "Received response from r/investing\n",
      "Parsed 100 posts from r/investing\n",
      "Collected 1001 unique posts from r/personalfinance\n",
      "Collected 943 unique posts from r/investing\n",
      "Total posts collected so far: 1944\n",
      "Test: Break Time!\n",
      "Beginning Loop...\n",
      "Requesting posts from r/personalfinance\n",
      "Received response from r/personalfinance\n",
      "Parsed 100 posts from r/personalfinance\n",
      "Requesting posts from r/investing\n",
      "Received response from r/investing\n",
      "Parsed 100 posts from r/investing\n",
      "Collected 1001 unique posts from r/personalfinance\n",
      "Collected 943 unique posts from r/investing\n",
      "Total posts collected so far: 1944\n",
      "Test: Break Time!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Waiting before looping \u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest: Break Time!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop to collect posts\n",
    "while True:\n",
    "    try:\n",
    "        # Print statement to make sure the loop is looping\n",
    "        print('Beginning Loop...')\n",
    "        # Get access token\n",
    "        token = get_token()\n",
    "\n",
    "        # Pull posts from both subreddits\n",
    "        personalfinance_posts, last_personalfinance_id = get_posts('personalfinance', token, limit=100, before=last_personalfinance_id)\n",
    "        investing_posts, last_investing_id = get_posts('investing', token, limit=100, before= last_investing_id)\n",
    "        \n",
    "        # Filter unique posts\n",
    "        personalfinance_unique = unique_filter(all_posts, personalfinance_posts)\n",
    "        investing_unique = unique_filter(all_posts, investing_posts)\n",
    "\n",
    "        # Append the unique posts to the main DataFrame\n",
    "        all_posts = pd.concat([all_posts, personalfinance_unique, investing_unique], ignore_index=True)\n",
    "        \n",
    "        # Remove duplicates \n",
    "        all_posts.drop_duplicates(subset=['id'], inplace=True)\n",
    "\n",
    "        # Save data to CSV after each iteration\n",
    "        all_posts.to_csv('subreddit-data.csv', mode='w', header=True, index=False)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Collected {len(all_posts[all_posts['subreddit'] == 'personalfinance'])} unique posts from r/personalfinance\")\n",
    "        print(f\"Collected {len(all_posts[all_posts['subreddit'] == 'investing'])} unique posts from r/investing\")\n",
    "        print(f\"Total posts collected so far: {len(all_posts)}\")\n",
    "\n",
    "        # Check if both subreddits have 3500 unique posts\n",
    "        if len(all_posts[all_posts['subreddit'] == 'personalfinance']) >= 3000 and len(all_posts[all_posts['subreddit'] == 'investing']) >= 3000:\n",
    "            print(\"Collected 3000 unique posts from both subreddits. Stopping the script.\")\n",
    "            break\n",
    "\n",
    "        # Waiting before looping \n",
    "        print(\"Test: Break Time!\")\n",
    "        time.sleep(61)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        # Retry after 45 seconds if there is an error\n",
    "        time.sleep(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c027b2-6e94-4e10-add8-9dd969d099bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
