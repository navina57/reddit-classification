{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1464a1-dee4-423a-ab7b-224ddf512af5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb32fa-0d28-487f-bd61-810f008220eb",
   "metadata": {},
   "source": [
    "**REFER TO DATA_COLLECTION NOTEBOOK IF YOU WANT TO SEE REQUESTS METHOD FOR SCRAPING, THIS NOTEBOOK USES PRAW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8a11d7-ce38-4b19-8920-779159726a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bebef4b-28a3-4c25-971f-f8a0c61de3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6daff-8e9c-40f1-8169-75611f9200dd",
   "metadata": {},
   "source": [
    "### API credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c674f24-59d0-42ad-b787-066d274637c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id = 'NSeSVr03ZJ8ov2YBVvK6vw',\n",
    "    client_secret =  'VJbMqoBH0yMzhUXtvrtBUY6IgwLcXQ',\n",
    "    user_agent = 'navi dsb-826',\n",
    "    username = 'OkCommunity6752',\n",
    "    password =  'Magnum12' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2303d20-c632-48df-9422-ecdf05646ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the existing CSV filed \n",
    "def load_existing_data(file):\n",
    "    try:\n",
    "        return pd.read_csv(file)\n",
    "    except FileNotFoundError: \n",
    "        # return an empty dataframe if file does not exist\n",
    "        return pd.DataFrame(columns=['subreddit', 'title', 'body', 'created', 'score', 'num_comments', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcc2f08-cf85-4267-98b9-b57e174e6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get posts from subreddit\n",
    "def get_old_posts(subreddit_name, limit=100):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    # Create list of posts to append to \n",
    "    posts_list = []\n",
    "\n",
    "    # Get posts \n",
    "    for post in subreddit.new(limit = limit): \n",
    "        posts_list.append({\n",
    "            'subreddit': subreddit_name, \n",
    "            'title': post.title,\n",
    "            'body': post.selftext,\n",
    "            'created': post.created_utc,\n",
    "            'score': post.score,\n",
    "            'num_comments': post.num_comments,\n",
    "            'id': post.id\n",
    "        })\n",
    "    return pd.DataFrame(posts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a54f48-c0d4-43e2-b098-5bd627887984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter unique posts\n",
    "def unique_filter(df, new_posts):\n",
    "    return new_posts[~new_posts['id'].isin(df['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3672d-e6e4-4aae-98d4-c95c8965fe86",
   "metadata": {},
   "source": [
    "### Function to Pull data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e1585d-6142-432f-a1d6-5951afbfbed2",
   "metadata": {},
   "source": [
    "I initially used requests to pull data from Reddit's API. However, after attending office hours, I learned about praw and decided to try it out myself. Using praw helped simply the processing of getting data on a day to day basis as I simply had to run one block of code to pull data. If you want to see how I used requests to scrape my data, refer to the other data collection notebook labelled \"data-collection.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02057d79-ff32-4f2b-bc77-59452fa67e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_posts(subreddit_name, file, limit = 100):\n",
    "    print(f'Collecting posts from {subreddit_name}')\n",
    "\n",
    "    # Load the existing posts \n",
    "    existing_posts = load_existing_data(file)\n",
    "\n",
    "    # Get new posts \n",
    "    new_posts = get_old_posts(subreddit_name, limit = limit)\n",
    "\n",
    "    # Filter out duplicates\n",
    "    unique_posts = unique_filter(existing_posts, new_posts)\n",
    "\n",
    "    if not unique_posts.empty: \n",
    "        # Append unique posts to exisiting csv \n",
    "        all_posts = pd.concat([existing_posts, unique_posts], ignore_index = True)\n",
    "        all_posts.drop_duplicates(subset = ['id'], inplace = True)\n",
    "\n",
    "        # Save the data\n",
    "        all_posts.to_csv(file, index = False)\n",
    "        print(f'{len(unique_posts)} new posts added from {subreddit_name}. Total posts: {len(all_posts)}')\n",
    "    else: \n",
    "        print(f'No new posts for {subreddit_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839fc8a-b9a6-4f9a-9de7-00051521facf",
   "metadata": {},
   "source": [
    "### Collect Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51b15eb-70ac-41c5-8cc6-40abd21cb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting posts from personalfinance\n",
      "80 new posts added from personalfinance. Total posts: 2628\n",
      "Collecting posts from investing\n",
      "15 new posts added from investing. Total posts: 2643\n"
     ]
    }
   ],
   "source": [
    "subreddits = ['personalfinance', 'investing']\n",
    "csv_file = '../data/subreddit-data.csv'\n",
    "\n",
    "for subreddit in subreddits: \n",
    "    update_posts(subreddit, csv_file, limit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea79da-a05f-4d2a-a36c-163b430e6ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
